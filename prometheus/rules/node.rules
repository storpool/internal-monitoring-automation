---
groups:
  - name: Node rules
    rules:
      - alert: RebootRequired
        expr: 'node_reboot_required > 0'
        labels:
          severity: warning
        annotations:
          description: '{{ $labels.instance }} requires a reboot.'
          summary: 'Host `{{ $labels.instance }}` - reboot required'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostOutOfMemory
        expr: 'node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 5'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: 'Host has less than 5% available memory'
          description: 'Host `{{ $labels.instance }}` has only {{ printf "%.2f" $value }}% memory available.'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostMemoryUnderMemoryPressure
        expr: 'rate(node_vmstat_pgmajfault[1m]) > 1000'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: 'Host is under memory pressure'
          description: 'Host `{{ $labels.instance }}` is under heavy memory pressure. It has high rate of major page faults.'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      # Please add ignored mountpoints in node_exporter parameters like
      # "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/)".
      # Same rule using "node_filesystem_free_bytes" will fire when disk fills for non-root users.
      - alert: HostOutOfDiskSpace
        expr: '(node_filesystem_avail_bytes{fstype !~ "procfs"} * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: 'Host has less than 10% of available disk space'
          description: 'Disk `{{ $labels.device }}` on `{{ $labels.instance }}` has only {{ printf "%.2f" $value }}% available space.'

      - alert: HostOutOfDiskSpace
        expr: '(node_filesystem_avail_bytes{fstype !~ "procfs"} * 100) / node_filesystem_size_bytes < 5 and ON (instance, device, mountpoint) node_filesystem_readonly == 0'
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: 'Host has less than 5% of available disk space'
          description: 'Disk `{{ $labels.device }}` on `{{ $labels.instance }}` has only {{ printf "%.2f" $value }}% available space.'

      # Please add ignored mountpoints in node_exporter parameters like
      # "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/)".
      # Same rule using "node_filesystem_free_bytes" will fire when disk fills for non-root users.
      - alert: HostDiskWillFillIn24Hours
        expr: '(node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly == 0'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: 'Host `{{ $labels.instance }}` is expected fill its filesystem in the next 24 hours'
          description: 'Device `{{ $labels.device }}` mounted at `{{ $labels.mountpoint }}` on host `{{ $labels.instance }}` is predicted to run out of space within the next 24 hours at current write rate'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostRootFSOutOfInodes
        expr: 'node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint="/rootfs"} * 100 < 10 and ON (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/rootfs"} == 0'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: 'Host `{{ $labels.instance }}` root filesystem has less than 10% free inodes left'
          description: 'Root filesystem on disk `{{ $labels.device }}` has {{ printf "%.2f" $value }} free inodes.'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostRootFSInodesWillFillIn24Hours
        expr: 'node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint="/rootfs"} * 100 < 10 and predict_linear(node_filesystem_files_free{mountpoint="/rootfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/rootfs"} == 0'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: 'Host `{{ $labels.instance }}` root filesystem inodes will fill in 24 hours.'
          description: 'Root filesystem is predicted to run out of inodes within the next 24 hours at current write rate'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostUnusualDiskReadLatency
        expr: 'rate(node_disk_read_time_seconds_total{type="bare-metal"}[1m]) / rate(node_disk_reads_completed_total{type="bare-metal"}[1m]) > 0.1 and rate(node_disk_reads_completed_total{type="bare-metal"}[1m]) > 0'
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: 'Host unusual disk read latency (instance {{ $labels.instance }})'
          description: 'Disk {{ $labels.device }} on host {{ $labels.instance }} read latency is growing ({{ printf "%.2f" $value }} ms)'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostUnusualDiskWriteLatency
        expr: 'rate(node_disk_write_time_seconds_total{type="bare-metal"}[1m]) / rate(node_disk_writes_completed_total{type="bare-metal"}[1m]) > 0.1 and rate(node_disk_writes_completed_total{type="bare-metal"}[1m]) > 0'
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: 'Host unusual disk write latency (instance {{ $labels.instance }})'
          description: 'Disk {{ $labels.device }} on host {{ $labels.instance }} write latency is growing ({{ printf "%.2f" $value }} ms)'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostHighCPULoad
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[10m])) * 100) > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: 'Host CPU load is more than 80%'
          description: 'Host `{{ $labels.instance }}` CPU load is {{ printf "%.2f" $value }}.'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostCPUStealNoisyNeighbor
        expr: avg by(instance) (rate(node_cpu_seconds_total{mode="steal"}[5m])) * 100 > 20
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: 'Host CPU steal time is more than 10%'
          description: 'Host `{{ $labels.instance }}` CPU steal time is {{ printf "%.0f" $value }}%.'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      # 1000 context switches is an arbitrary number.
      # Alert threshold depends on nature of application.
      # Please read: https://github.com/samber/awesome-prometheus-alerts/issues/58
      - alert: HostContextSwitching
        expr: '(rate(node_context_switches_total[5m])) / (count without(cpu, mode) (node_cpu_seconds_total{mode="idle"})) > 10000'
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: 'Host context switching growiing'
          description: 'Host `{{ $labels.instance }}` context switching is growing on node.'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostSwapIsFillingUp
        expr: '(1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100 > 80'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: 'Host swap is filling up has less than 20% left.'
          description: 'Swap on host `{{ $labels.instance }}` is {{ printf "%.2f" $value }} full.'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostRaidArrayGotInactive
        expr: 'node_md_state{state="inactive"} > 0'
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: Host RAID array got inactive (instance {{ $labels.instance }})
          description: "RAID array {{ $labels.device }} is in degraded state due to one or more disks failures. Number of spare drives is insufficient to fix issue automatically.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostRaidDiskFailure
        expr: node_md_disks{state="failed"} > 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host RAID disk failure (instance {{ $labels.instance }})
          description: "At least one device in RAID array on {{ $labels.instance }} failed. Array {{ $labels.md_device }} needs attention and possibly a disk swap\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      #- alert: HostKernelVersionDeviations
      #  expr: count(sum(label_replace(node_uname_info, "kernel", "$1", "release", "([0-9]+.[0-9]+.[0-9]+).*")) by (kernel)) > 1
      #  for: 6h
      #  labels:
      #    severity: warning
      #  annotations:
      #    summary: Host kernel version deviations (instance {{ $labels.instance }})
      #    description: "Different kernel versions are running\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostOOMKillDetected
        expr: 'increase(node_vmstat_oom_kill[1m]) > 0'
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: 'Host OOM kill detected'
          description: 'OOM kill detected on host `{{ $labels.instance }}`.'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostEdacCorrectableErrorsDetected
        expr: 'increase(node_edac_correctable_errors_total[5m]) > 0'
        for: 10m
        labels:
          severity: info
        annotations:
          summary: 'Host EDAC correctable errors detected'
          description: 'Host {{ $labels.instance }} has had {{ printf "%.0f" $value }} correctable memory errors on controller {{ $labels.controller }} reported by EDAC in the last 5 minutes.'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostEdacUncorrectableErrorsDetected
        expr: 'node_edac_uncorrectable_errors_total > 0'
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: 'Host EDAC uncorrectable errors detected'
          description: 'Host {{ $labels.instance }} has had {{ printf "%.0f" $value }} uncorrectable memory errors on controller {{ $labels.controller }} reported by EDAC in the last 5 minutes.'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostNetworkReceiveErrors
        expr: 'rate(node_network_receive_errs_total[2m]) / rate(node_network_receive_packets_total[2m]) > 0.01'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: 'Host has network receive errors'
          description: 'Host {{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} receive errors in the last two minutes.'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostNetworkTransmitErrors
        expr: 'rate(node_network_transmit_errs_total[2m]) / rate(node_network_transmit_packets_total[2m]) > 0.01'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: 'Host has network transmit errors'
          description: 'Host {{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} transmit errors in the last two minutes.'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostNetworkInterfaceSaturated
        expr: 'increase(node_network_transmit_drop_total{device!~"^tap.*|^one-.*", type="bare-metal"}[30m]) / increase(node_network_transmit_bytes_total{device!~"^tap.*|^one-.*", type="bare-metal"}[30m]) > 0.8 < 10000'
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: 'Host network interface saturated'
          description: 'Network interface {{ $labels.device }} on {{ $labels.instance }} is getting overloaded.'
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostConntrackLimit
        expr: node_nf_conntrack_entries / node_nf_conntrack_entries_limit > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: 'Host conntrack limit'
          description: "The number of conntrack on host `{{ $labels.instance }}` is approaching limit."
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostClockSkew
        expr: '(node_timex_offset_seconds > 0.05 and deriv(node_timex_offset_seconds[5m]) >= 0) or (node_timex_offset_seconds < -0.05 and deriv(node_timex_offset_seconds[5m]) <= 0)'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: 'Host clock skew'
          description: "Clock skew detected on host `{{ $labels.instance }}`. Clock is out of sync."
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'

      - alert: HostClockNotSynchronising
        expr: 'min_over_time(node_timex_sync_status[1m]) == 0 and node_timex_maxerror_seconds >= 16'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: 'Host clock not synchronising'
          description: "Clock on host `{{ $labels.instance }}` not synchronising."
          node_stats_url: '{{ $externalLabels.grafana_url }}/d/rYdddlPWk/node-status?orgId=1&var-DS_PROMETHEUS=default&var-job=node-exporter&var-node={{ $labels.instance }}'
